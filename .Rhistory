post_scurve11 = gcomp_bayes(post_draws, 1000, rule1, tau_vec)
post_scurve11_weib = gcomp_bayes_weib(post_draws_weib, 1000, rule1, tau_vec)
par(mfrow=c(1,2))
plot(tau_vec, rowMeans(post_scurve11), col='white', type='l', lty=1, ylim=c(0,1),
main=TeX('Marginal Survival Curves Under Rule $A_k = I( L_k > \\tau )$'),
ylab = TeX('$S^r(t)$'), axes=F,
xlab='Time, t', cex.main=.9, cex.lab=1.1, cex.axis=1.1)
pci11 = apply(post_scurve11, 1, quantile, probs=c(.025, .975))
polygon(c(tau_vec,rev(tau_vec)),c(pci11[1,],rev(pci11[2,])),
col = rgb(1, 0, 0, .2), border = FALSE)
# legend('topright',
#        legend = c(TeX('Rule 1: $\\tau =3$'),
#                   TeX('Rule 2: $\\tau =0$') ),
#        fill=c(rgb(1, 0, 0, .2), rgb(1,.65,0, .2)), cex = .8  )
lines(tau_vec, strue11, col='red', lty=2)
# lines(tau_vec, strue10, col='orange', lty=2)
at_vec = seq(0, 30, 5)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
labs = paste0( at_vec,"\n % at risk \n " , perc)
axis(side = 1, at = at_vec, labels = labs, pos = 0, padj = .7)
axis(side = 2, at = seq(0, 1, .2), labels = seq(0, 1, .2))
plot(tau_vec, rowMeans(post_scurve11_weib), col='white', type='l', lty=1, ylim=c(0,1),
main=TeX('Marginal Survival Curves Under Rule $A_k = I( L_k > \\tau )$'),
ylab = TeX('$S^r(t)$'), axes=F,
xlab='Time, t', cex.main=.9, cex.lab=1.1, cex.axis=1.1)
pci11 = apply(post_scurve11_weib, 1, quantile, probs=c(.025, .975))
polygon(c(tau_vec,rev(tau_vec)),c(pci11[1,],rev(pci11[2,])),
col = rgb(1, 0, 0, .2), border = FALSE)
# legend('topright',
#        legend = c(TeX('Rule 1: $\\tau =3$'),
#                   TeX('Rule 2: $\\tau =0$') ),
#        fill=c(rgb(1, 0, 0, .2), rgb(1,.65,0, .2)), cex = .8  )
lines(tau_vec, strue11, col='red', lty=2)
# lines(tau_vec, strue10, col='orange', lty=2)
at_vec = seq(0, 30, 5)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
labs = paste0( at_vec,"\n % at risk \n " , perc)
axis(side = 1, at = at_vec, labels = labs, pos = 0, padj = .7)
axis(side = 2, at = seq(0, 1, .2), labels = seq(0, 1, .2))
post_scurve11 = gcomp_bayes(post_draws, 2000, rule1, tau_vec)
post_scurve11_weib = gcomp_bayes_weib(post_draws_weib, 2000, rule1, tau_vec)
par(mfrow=c(1,2))
plot(tau_vec, rowMeans(post_scurve11), col='white', type='l', lty=1, ylim=c(0,1),
main=TeX('Marginal Survival Curves Under Rule $A_k = I( L_k > \\tau )$'),
ylab = TeX('$S^r(t)$'), axes=F,
xlab='Time, t', cex.main=.9, cex.lab=1.1, cex.axis=1.1)
pci11 = apply(post_scurve11, 1, quantile, probs=c(.025, .975))
polygon(c(tau_vec,rev(tau_vec)),c(pci11[1,],rev(pci11[2,])),
col = rgb(1, 0, 0, .2), border = FALSE)
# legend('topright',
#        legend = c(TeX('Rule 1: $\\tau =3$'),
#                   TeX('Rule 2: $\\tau =0$') ),
#        fill=c(rgb(1, 0, 0, .2), rgb(1,.65,0, .2)), cex = .8  )
lines(tau_vec, strue11, col='red', lty=2)
# lines(tau_vec, strue10, col='orange', lty=2)
at_vec = seq(0, 30, 5)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
labs = paste0( at_vec,"\n % at risk \n " , perc)
axis(side = 1, at = at_vec, labels = labs, pos = 0, padj = .7)
axis(side = 2, at = seq(0, 1, .2), labels = seq(0, 1, .2))
plot(tau_vec, rowMeans(post_scurve11_weib), col='white', type='l', lty=1, ylim=c(0,1),
main=TeX('Marginal Survival Curves Under Rule $A_k = I( L_k > \\tau )$'),
ylab = TeX('$S^r(t)$'), axes=F,
xlab='Time, t', cex.main=.9, cex.lab=1.1, cex.axis=1.1)
pci11 = apply(post_scurve11_weib, 1, quantile, probs=c(.025, .975))
polygon(c(tau_vec,rev(tau_vec)),c(pci11[1,],rev(pci11[2,])),
col = rgb(1, 0, 0, .2), border = FALSE)
# legend('topright',
#        legend = c(TeX('Rule 1: $\\tau =3$'),
#                   TeX('Rule 2: $\\tau =0$') ),
#        fill=c(rgb(1, 0, 0, .2), rgb(1,.65,0, .2)), cex = .8  )
lines(tau_vec, strue11, col='red', lty=2)
# lines(tau_vec, strue10, col='orange', lty=2)
at_vec = seq(0, 30, 5)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
labs = paste0( at_vec,"\n % at risk \n " , perc)
axis(side = 1, at = at_vec, labels = labs, pos = 0, padj = .7)
axis(side = 2, at = seq(0, 1, .2), labels = seq(0, 1, .2))
post_scurve11 = gcomp_bayes(post_draws, 3000, rule1, tau_vec)
post_scurve11_weib = gcomp_bayes_weib(post_draws_weib, 3000, rule1, tau_vec)
par(mfrow=c(1,2))
plot(tau_vec, rowMeans(post_scurve11), col='white', type='l', lty=1, ylim=c(0,1),
main=TeX('Marginal Survival Curves Under Rule $A_k = I( L_k > \\tau )$'),
ylab = TeX('$S^r(t)$'), axes=F,
xlab='Time, t', cex.main=.9, cex.lab=1.1, cex.axis=1.1)
pci11 = apply(post_scurve11, 1, quantile, probs=c(.025, .975))
polygon(c(tau_vec,rev(tau_vec)),c(pci11[1,],rev(pci11[2,])),
col = rgb(1, 0, 0, .2), border = FALSE)
# legend('topright',
#        legend = c(TeX('Rule 1: $\\tau =3$'),
#                   TeX('Rule 2: $\\tau =0$') ),
#        fill=c(rgb(1, 0, 0, .2), rgb(1,.65,0, .2)), cex = .8  )
lines(tau_vec, strue11, col='red', lty=2)
# lines(tau_vec, strue10, col='orange', lty=2)
at_vec = seq(0, 30, 5)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
labs = paste0( at_vec,"\n % at risk \n " , perc)
axis(side = 1, at = at_vec, labels = labs, pos = 0, padj = .7)
axis(side = 2, at = seq(0, 1, .2), labels = seq(0, 1, .2))
plot(tau_vec, rowMeans(post_scurve11_weib), col='white', type='l', lty=1, ylim=c(0,1),
main=TeX('Marginal Survival Curves Under Rule $A_k = I( L_k > \\tau )$'),
ylab = TeX('$S^r(t)$'), axes=F,
xlab='Time, t', cex.main=.9, cex.lab=1.1, cex.axis=1.1)
pci11 = apply(post_scurve11_weib, 1, quantile, probs=c(.025, .975))
polygon(c(tau_vec,rev(tau_vec)),c(pci11[1,],rev(pci11[2,])),
col = rgb(1, 0, 0, .2), border = FALSE)
# legend('topright',
#        legend = c(TeX('Rule 1: $\\tau =3$'),
#                   TeX('Rule 2: $\\tau =0$') ),
#        fill=c(rgb(1, 0, 0, .2), rgb(1,.65,0, .2)), cex = .8  )
lines(tau_vec, strue11, col='red', lty=2)
# lines(tau_vec, strue10, col='orange', lty=2)
at_vec = seq(0, 30, 5)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
labs = paste0( at_vec,"\n % at risk \n " , perc)
axis(side = 1, at = at_vec, labels = labs, pos = 0, padj = .7)
axis(side = 2, at = seq(0, 1, .2), labels = seq(0, 1, .2))
library(LaplacesDemon)
library(flexsurv)
library(latex2exp)
library(mvtnorm)
setwd("/Users/arman/google_drive/Research/BNP_DTR/simulations/BNP_PH_cc_multivar/")
source('data_sim_4tp_helper_real.R')
## -------------------- Data Generating Process ----------------------------- ##
set.seed(1991)
N = 1000
M = 1000
tau_vec = seq(0, 30, .1)
#tau_vec = c(5, 15, 25)
rule1 = function(z) 1*(z > -1)
#rule2 = function(z) 1*(z > 2)
d_truth = sim_data(1000000, rule1)
strue11 = sapply(tau_vec, function(tau) mean(d_truth$obs_time>tau) )
plot(tau_vec, strue11, type='l')
at_vec = seq(0, 30, 5)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
d = sim_data(N)
at_vec = seq(0, 30, 1)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
perc
library(LaplacesDemon)
library(flexsurv)
library(latex2exp)
library(mvtnorm)
setwd("/Users/arman/google_drive/Research/BNP_DTR/simulations/BNP_PH_cc_multivar/")
source('data_sim_4tp_helper_real.R')
## -------------------- Data Generating Process ----------------------------- ##
set.seed(1991)
N = 1000
M = 1000
tau_vec = seq(0, 30, .1)
rule1 = function(z) 1*(z > -1)
do_all = function(){
d_truth = sim_data(1000000, rule1)
strue11 = sapply(tau_vec, function(tau) mean(d_truth$obs_time>tau) )
plot(tau_vec, strue11, type='l')
## --------------------   Simualte Data   ----------------------------------##
d = sim_data(N)
# plot(survfit(Surv(d$obs_time, event=d$delta) ~ 1), mark.time = T)
## mathces data: ~40% death. ~60$ complete course before death/dropout
# table(d$kappa)/1000
# mean(d$delta)
## --------------------   Calculate PH Estimates   -------------------------##
source('BNP_PH_helpers/mcmc_4tp.R')
source('BNP_PH_helpers/mcmc_4tp_helper.R')
source('BNP_PH_helpers/gcomp_4tp_helper.R')
### initial jumping dist covariances...to be tuned during adaptation period.
jump_cov_tau1 = .001*diag(7)
jump_cov_tau2 = jump_cov_tau3 = .001*diag(10)
jump_cov_T1  = .001*diag(7)
jump_cov_T2 = jump_cov_T3 = jump_cov_T4 = .001*diag(10)
st = Sys.time()
post_draws = bayes_dtr_mcmc(d,10000, 5000, 1, adapt_start=2000, adapt_end = 5000)
post_scurve11 = gcomp_bayes(post_draws, 3000, rule1, tau_vec)
ed = Sys.time()
ed - st
# par(mfrow=c(2, 4))
# for(t in 1:2){
#   plot(post_draws$haztauk[5, t, ], type='l'); #abline(v=2000, col='red'); abline(v=3000, col='red');
#   plot(post_draws$haztauk[6, t, ], type='l'); #abline(v=2000, col='red'); abline(v=3000, col='red');
#   plot(post_draws$haztauk[7, t, ], type='l'); #abline(v=2000, col='red'); abline(v=3000, col='red');
#   plot(post_draws$haztauk[8, t, ], type='l'); #abline(v=2000, col='red'); abline(v=3000, col='red');
# }
# par(mfrow=c(3, 4))
# for(t in 1:3){
#   plot(post_draws$hazTk[1, t, ], type='l'); #abline(v=2000, col='red'); abline(v=3000, col='red');
#   plot(post_draws$hazTk[2, t, ], type='l'); #abline(v=2000, col='red'); abline(v=3000, col='red');
#   plot(post_draws$hazTk[3, t, ], type='l'); #abline(v=2000, col='red'); abline(v=3000, col='red');
#   plot(post_draws$hazTk[4, t, ], type='l'); #abline(v=2000, col='red'); abline(v=3000, col='red');
# }
# par(mfrow=c(3, 3))
# for(t in 1:3){
#   plot(post_draws$Vk_mu[1, t, ], type='l')
#   plot(post_draws$Vk_mu[2, t, ], type='l')
#   plot(post_draws$Vk_mu[3, t, ], type='l')
# }
## --------------------   Calculate Exp Estimates   ------------------------##
# source('Exp_helpers/mcmc_4tp.R')
# source('Exp_helpers/mcmc_4tp_helper.R')
# source('Exp_helpers/gcomp_4tp_helper.R')
# post_draws_exp = bayes_dtr_mcmc_exp(d, 20000, 5000, 5)
# post_scurve11_exp = gcomp_bayes_exp(post_draws_exp, M, rule1, tau_vec)
#post_scurve10_exp = gcomp_bayes_exp(post_draws_exp, M, rule2, tau_vec)
## --------------------   Calculate Weibull Estimates ----------------------##
source('Weib_helpers//mcmc_4tp.R')
source('Weib_helpers/mcmc_4tp_helper.R')
source('Weib_helpers/gcomp_4tp_helper.R')
### initial jumping dist covariances...to be tuned during adaptation period.
# jump_cov_tau1 = .001*diag(7)
# jump_cov_tau2 = jump_cov_tau3 = .001*diag(10)
# jump_cov_T1  = .001*diag(7)
# jump_cov_T2 = jump_cov_T3 = jump_cov_T4 = .001*diag(10)
st = Sys.time()
post_draws_weib = bayes_dtr_mcmc_weib(d,10000, 5000, 1, adapt_start=2000, adapt_end = 5000)
post_scurve11_weib = gcomp_bayes_weib(post_draws_weib, 3000, rule1, tau_vec)
ed = Sys.time()
ed-st
# par(mfrow=c(2,4))
# for(t in 1:4){ plot(post_draws_weib$w_T[1, t , ], type='l') }
# for(t in 1:4){ plot(post_draws_weib$w_T[2, t , ], type='l') }
#
# par(mfrow=c(2,3))
# for(t in 1:3){ plot(post_draws_weib$w_tau[1, t , ], type='l') }
# for(t in 1:3){ plot(post_draws_weib$w_tau[2, t , ], type='l') }
#
# par(mfrow=c(2,4))
# for(t in 1:4){ plot(post_draws_weib$haztauk[t, 1 , ], type='l') }
# for(t in 1:4){ plot(post_draws_weib$haztauk[t, 2 , ], type='l') }
#
# par(mfrow=c(3,4))
# for(t in 1:4){ plot(post_draws_weib$hazTk[t, 1 , ], type='l') }
# for(t in 1:4){ plot(post_draws_weib$hazTk[t, 2 , ], type='l') }
# for(t in 1:4){ plot(post_draws_weib$hazTk[t, 3 , ], type='l') }
#
# par(mfrow=c(2,2))
# for(t in 1:2){ plot(post_draws_weib$hazT1[, t], type='l') }
# for(t in 1:2){ plot(post_draws_weib$haztau1[, t], type='l') }
## --------------------   Calculate Naive Estimates   ----------------------##
## --------------------  Process Results            ------------------------##
res_ph = data.frame(mod='ph', time=tau_vec,
post_mean=rowMeans(post_scurve11),
post_lwr = apply(post_scurve11,1, quantile, probs=.025 ),
post_upr = apply(post_scurve11,1, quantile, probs=.975 ))
# res_exp = data.frame(mod='exp', time=tau_vec,
#                     post_mean=rowMeans(post_scurve11_exp),
#                     post_lwr = apply(post_scurve11_exp,1, quantile, probs=.025 ),
#                     post_upr = apply(post_scurve11_exp,1, quantile, probs=.975 ))
res_weib = data.frame(mod='weib', time=tau_vec,
post_mean=rowMeans(post_scurve11_weib),
post_lwr = apply(post_scurve11_weib,1, quantile, probs=.025 ),
post_upr = apply(post_scurve11_weib,1, quantile, probs=.975 ))
res = rbind(res_ph, res_exp, res_weib)
return(res)
}
d_truth = sim_data(1000000, rule1)
strue11 = sapply(tau_vec, function(tau) mean(d_truth$obs_time>tau) )
d = sim_data(N)
hist(d$U1)
hist(d$U2)
hist(d$U3)
hist(d$U4)
hist(d$U1)
hist(d$U2)
hist(d$U3)
hist(d$U4)
hist(d$U5)
source("~/google_drive/Research/BNP_DTR/simulations/BNP_PH_cc_multivar/BNP_PH_helpers/mcmc_4tp_helper.R")
# plot(survfit(Surv(d$obs_time, event=d$delta) ~ 1), mark.time = T)
## mathces data: ~40% death. ~60$ complete course before death/dropout
# table(d$kappa)/1000
# mean(d$delta)
## --------------------   Calculate PH Estimates   -------------------------##
source('BNP_PH_helpers/mcmc_4tp.R')
source('BNP_PH_helpers/mcmc_4tp_helper.R')
source('BNP_PH_helpers/gcomp_4tp_helper.R')
### initial jumping dist covariances...to be tuned during adaptation period.
jump_cov_tau1 = .001*diag(7)
jump_cov_tau2 = jump_cov_tau3 = .001*diag(10)
jump_cov_T1  = .001*diag(7)
jump_cov_T2 = jump_cov_T3 = jump_cov_T4 = .001*diag(10)
st = Sys.time()
post_draws = bayes_dtr_mcmc(d,10000, 5000, 1, adapt_start=2000, adapt_end = 5000)
post_scurve11 = gcomp_bayes(post_draws, 3000, rule1, tau_vec)
ed = Sys.time()
ed - st
par(mfrow=c(1,2))
plot(tau_vec, rowMeans(post_scurve11), col='white', type='l', lty=1, ylim=c(0,1),
main=TeX('Marginal Survival Curves Under Rule $A_k = I( L_k > \\tau )$'),
ylab = TeX('$S^r(t)$'), axes=F,
xlab='Time, t', cex.main=.9, cex.lab=1.1, cex.axis=1.1)
pci11 = apply(post_scurve11, 1, quantile, probs=c(.025, .975))
polygon(c(tau_vec,rev(tau_vec)),c(pci11[1,],rev(pci11[2,])),
col = rgb(1, 0, 0, .2), border = FALSE)
# legend('topright',
#        legend = c(TeX('Rule 1: $\\tau =3$'),
#                   TeX('Rule 2: $\\tau =0$') ),
#        fill=c(rgb(1, 0, 0, .2), rgb(1,.65,0, .2)), cex = .8  )
lines(tau_vec, strue11, col='red', lty=2)
# lines(tau_vec, strue10, col='orange', lty=2)
at_vec = seq(0, 30, 5)
at_risk = function(t) mean(d$obs_time > t)
perc = sapply(at_vec, at_risk)
labs = paste0( at_vec,"\n % at risk \n " , perc)
axis(side = 1, at = at_vec, labels = labs, pos = 0, padj = .7)
axis(side = 2, at = seq(0, 1, .2), labels = seq(0, 1, .2))
library(LaplacesDemon)
library(flexsurv)
library(latex2exp)
library(mvtnorm)
setwd("/Users/arman/google_drive/Research/BNP_DTR/simulations/BNP_PH_cc_multivar/")
source('data_sim_4tp_helper_real.R')
## -------------------- Data Generating Process ----------------------------- ##
set.seed(1991)
N = 1000
M = 1000
tau_vec = seq(0, 30, .1)
rule1 = function(z) 1*(z > 0)
d_truth = sim_data(1000000, rule1)
strue11 = sapply(tau_vec, function(tau) mean(d_truth$obs_time>tau) )
plot(tau_vec, strue11, type='l')
d = sim_data(N)
hist(d$U1)
max(d$U1)
seq(0, 5.5555, lenght.out=20)
seq(0, 5.5555, length.out=20)
max(d$U2)
max(d$U2, na.rm=T)
seq(0, 7.289552, length.out=20)
plot( seq(0, 7.289552, length.out=20), quantiles(d$U2, probs=seq(.05, 1, .05)) )
plot( seq(0, 7.289552, length.out=20), quantile(d$U2, probs=seq(.05, 1, .05)) )
plot( seq(0, 7.289552, length.out=20), quantile(d$U2, probs=seq(.05, 1, .05)), na.rm=T )
plot( seq(0, 7.289552, length.out=20), quantile(d$U2, probs=seq(.05, 1, .05), na.rm=T) )
plot( seq(0, max(d$U1), length.out=20), quantile(d$U2, probs=seq(.05, 1, .05), na.rm=T) )
plot( seq(0, max(d$U1), length.out=20), quantile(d$U1, probs=seq(.05, 1, .05), na.rm=T) )
plot( seq(0, max(d$U3), length.out=20), quantile(d$U3, probs=seq(.05, 1, .05), na.rm=T) )
plot( seq(0, max(d$U3, na.rm=T), length.out=20), quantile(d$U3, probs=seq(.05, 1, .05), na.rm=T) )
summary(d$U3)
plot( seq(0, max(d$U4, na.rm=T), length.out=20), quantile(d$U4, probs=seq(.05, 1, .05), na.rm=T) )
abline(0,1)
library(LaplacesDemon)
library(dplyr)
library(tidyr)
setwd("~/google_drive/Research/BNP_DTR/simulations/BNP_PH_cc_multivar/")
source("data_sim_4tp_helper_real.R")
rule1 = function(z) 1*(z > 0)
tau_vec = c(5, 10, 15, 20)
set.seed(1991)
d_truth = sim_data(1000000, rule = rule1)
strue11 = sapply(tau_vec, function(tau) mean(d_truth$obs_time>tau) )
d_truth = data.frame(time=tau_vec, truth = strue11)
# setwd("~/Downloads/")
# load("sim_res_500.Rdata")
# res500 = bind_rows(all_res, .id='iter')
# load("sim_res_1000.Rdata")
# res1000 = bind_rows(all_res, .id='iter')
#res = rbind(res500, res1000)
setwd("~/Downloads/")
load("sim_res_1.Rdata")
res1 =  bind_rows(all_res, .id='iter')
load("sim_res_2.Rdata")
res2 =  bind_rows(all_res, .id='iter')
load("sim_res_3.Rdata")
res3 =  bind_rows(all_res, .id='iter')
load("sim_res_4.Rdata")
res4 =  bind_rows(all_res, .id='iter')
load("sim_res_5.Rdata")
res5 =  bind_rows(all_res, .id='iter')
load("sim_res_6.Rdata")
res6 =  bind_rows(all_res, .id='iter')
load("sim_res_7.Rdata")
res7 =  bind_rows(all_res, .id='iter')
load("sim_res_8.Rdata")
res8 =  bind_rows(all_res, .id='iter')
load("sim_res_9.Rdata")
res9 =  bind_rows(all_res, .id='iter')
load("sim_res_10.Rdata")
res10 =  bind_rows(all_res, .id='iter')
res = rbind(res1, res2, res3, res4, res5, res6, res7, res8, res9, res10)
ress = res  %>%
left_join(d_truth, by='time') %>%
mutate(bias = post_mean - truth,
perc_bias= ((post_mean - truth)/truth)*100 ,
coverage_ind = post_lwr < truth & truth < post_upr  ) %>%
group_by(mod, time) %>%
summarise( bias = mean(bias),
perc_bias= mean(perc_bias),
coverage = mean( coverage_ind),
covsum = 1000-sum(coverage_ind),
empSE = sd( post_mean))
ress
library(LaplacesDemon)
library(dplyr)
library(tidyr)
setwd("~/google_drive/Research/BNP_DTR/simulations/BNP_PH_cc_multivar/")
source("data_sim_4tp_helper_real.R")
rule1 = function(z) 1*(z > 0)
tau_vec = c(5, 10, 15, 20)
set.seed(1991)
d_truth = sim_data(1000000, rule = rule1)
strue11 = sapply(tau_vec, function(tau) mean(d_truth$obs_time>tau) )
d_truth = data.frame(time=tau_vec, truth = strue11)
# setwd("~/Downloads/")
# load("sim_res_500.Rdata")
# res500 = bind_rows(all_res, .id='iter')
# load("sim_res_1000.Rdata")
# res1000 = bind_rows(all_res, .id='iter')
#res = rbind(res500, res1000)
setwd("~/Downloads/")
load("sim_res_1.Rdata")
res1 =  bind_rows(all_res, .id='iter')
load("sim_res_2.Rdata")
res2 =  bind_rows(all_res, .id='iter')
load("sim_res_3.Rdata")
res3 =  bind_rows(all_res, .id='iter')
load("sim_res_4.Rdata")
res4 =  bind_rows(all_res, .id='iter')
load("sim_res_5.Rdata")
res5 =  bind_rows(all_res, .id='iter')
load("sim_res_6.Rdata")
res6 =  bind_rows(all_res, .id='iter')
load("sim_res_7.Rdata")
res7 =  bind_rows(all_res, .id='iter')
load("sim_res_8.Rdata")
res8 =  bind_rows(all_res, .id='iter')
load("sim_res_9.Rdata")
res9 =  bind_rows(all_res, .id='iter')
load("sim_res_10.Rdata")
res10 =  bind_rows(all_res, .id='iter')
res = rbind(res1, res2, res3, res4, res5, res6, res7, res8, res9, res10)
ress = res  %>%
left_join(d_truth, by='time') %>%
mutate(bias = post_mean - truth,
perc_bias= ((post_mean - truth)/truth)*100 ,
coverage_ind = post_lwr < truth & truth < post_upr  ) %>%
group_by(mod, time) %>%
summarise( bias = mean(bias),
perc_bias= mean(perc_bias),
coverage = mean( coverage_ind),
covsum = 1000-sum(coverage_ind),
empSE = sd( post_mean))
ress
.07/.05
.01/.057
.01/.057
library(LaplacesDemon)
### Simulate true causal effect under true model with complete information
calc_truth = function(N = 10000000, A){
U = rbinom(N, 1, .5)
V = rbinom(N, 1, .5)
X = rbinom(N, 1, V*.6 + (1-V)*.4 )
Y = rbinom(N, 1, .2 + .1*V -.1*X + (.1*V + .1*X)*A + .2*U   )
return(mean(Y))
}
calc_truth2 = function(N = 10000000, A){
U = rbinom(N, 1, .5)
V = rbinom(N, 1, .5)
X = rbinom(N, 1, V*.6 + (1-V)*.4 )
M = rbinom(N, 1, .7*V + (1-V)*.3 +.2*U)
Y = rbinom(N, 1, .2 + .1*V -.1*X + (.1*V + .1*X)*A + .2*U )
return(mean(Y))
}
sim_incomplete_data = function(N=2000, violation=0){
V = rbinom(N, 1, .5)
U = rbinom(N, 1, .5)
X = rbinom(N, 1, V*.6 + (1-V)*.4 )
M = rbinom(N, 1, .7*V + (1-V)*.3 +.2*U)
A = rbinom(N, 1, .2 + .1*V + .1*X*M + .1*(V*X)*M  )
Y = rbinom(N, 1, .2 + .1*V -.1*X + (.1*V + .1*X)*A + .2*U )
d = data.frame(V=V, X=X, A=A, M=M, Y=Y)
d$X[d$M==0] = NA
return(d)
}
d = sim_incomplete_data()
ipw = function(violation=0){
d = sim_incomplete_data(violation=violation)
ps_mod_M1 = glm(data=d[d$M==1,], formula = A ~ X + V + X*V, family=binomial('logit'))
ps_mod_M0 = glm(data=d[d$M==0,], formula = A ~ V, family=binomial('logit'))
d$ps = NA
d$ps[d$M==1] = predict(ps_mod_M1, newdata = d[d$M==1,], type = 'response')
d$ps[d$M==0] = predict(ps_mod_M0, newdata = d[d$M==0,], type = 'response')
d$wght = ( d$A / d$ps ) + ( (1-d$A)/(1-d$ps) )
delta_hat  = weighted.mean(d$Y[d$A==1],d$wght[d$A==1] ) - weighted.mean(d$Y[d$A==0],d$wght[d$A==0] )
return(delta_hat)
}
## compute true causal effect (risk difference )
true_delta = calc_truth(A=1) - calc_truth(A=0)
true_delta
true_delta = calc_truth2(A=1) - calc_truth2(A=0)
true_delta
sim_res_v0 = replicate(5000, ipw(violation = 0))
mean(sim_res_v0)
(mean(sim_res_v0) - true_delta )/true_delta
blogdown:::preview_site()
setwd("~/google_drive/Software/personal_site/")
blogdown::build_dir()
blogdown::build_dir()
blogdown::build_site()
blogdown::render_site()
blogdown::serve_site()
getwd()
rmarkdown::serve_site()
rmarkdown::render_site()
blogdown::serve_site()
blogdown::build_site()
