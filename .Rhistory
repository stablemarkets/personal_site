plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.2, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.1, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.01, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
#
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.05, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.005, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.01, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.015, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.0175, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=2000, jump_v=.02, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
MH_cache$accept
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=10000, jump_v=.02, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
set.seed(1)
MH_cache <- mh_cache(beta_0 = c(0,0,0,0),
phi = 100, lambda = lambda, X = X, Y = Y,
mh_trials=20000, jump_v=.02, p=4)
# set.seed(1)
# MH_vanilla <- mh_vanilla(beta_0 = c(0,0,0,0),
#                        phi = 100, lambda = lambda, X = X, Y = Y,
#                        mh_trials=2000, jump_v=.7, p=4)
par(mfrow=c(2,2))
plot(MH_cache$post_draws[,1], type='l')
abline(h=0, col='red')
plot(MH_cache$post_draws[,2], type='l')
abline(h=2, col='red')
plot(MH_cache$post_draws[,3], type='l')
abline(h=1, col='red')
plot(MH_cache$post_draws[,4], type='l')
abline(h=-2, col='red')
devtools::install_github("stablemarkets/ChiRP")
library(ChiRP)
?ChiRP
?ChiRP::ZDPMix
getwed()
getwd()
devtools::install_github("stablemarkets/ChiRP")
library(ChiRP)
# Simulate data from sin() wave.
set.seed(3)
n <- 200
# training
x<-seq(1,10*pi, length.out = n) # confounder
y<-rnorm( n = length(x), sin(.5*x), .07*x)
d <- data.frame(x=x, y=y)
d$x <- scale(d$x) # standardize covariates
d_test <- data.frame(x=seq(1.5,2,.01))
set.seed(1)
NDP_res<-NDPMix(d_train = d, d_test = d_test,
formula = y ~ x,
burnin=100, iter = 200,
phi_y = c(5,10), beta_var_scale = 10000,
init_k = c(1,2), mu_scale = 2, tau_scale = .001)
c(0,4)<0
c(0,4)<0 | length(c(0,1))==1
c(0,4)<0 | length(c(0,1))==1
c(0,4)<0
set.seed(1)
NDP_res<-NDPMix(d_train = d, d_test = d_test,
formula = y ~ x,
burnin=100, iter = 200,
phi_y = c(5,10), beta_var_scale = 10000,
init_k = c(1,2), mu_scale = 2, tau_scale = .001)
devtools::install_github("stablemarkets/ChiRP")
library(ChiRP)
set.seed(1337)
# sample size
n <- 300
# true beta coefficient for x -> y
beta <- 0.5
# define logistic function for non-linear confounding
f <- function(x, p) {
p[1] / (1 + exp(-p[2] * (x - p[3])))
}
## generate the data
# d will be our data frame, z is the confounder
d <- data.frame(z=runif(n, min=-3.5, max=3.5))
# x is the independent var, non-linearly caused by
# the confounder plus noise
d$x <- f(d$z, c(-1,3,0)) + rnorm(nrow(d), sd=.1)
# y is the dependent var, non-linearly caused by
# z and linearly caused by x plus noise
d$y <- as.vector(scale(
f(d$z, c(1,3,0)) + beta*d$x + rnorm(nrow(d), sd=.1),
center=T, scale=F))
# check data
head(d)
d_test <- d
d_test$x <- d_test$x+.0000001
d_test <- d
d_test$x <- d_test$x+1
d_test_stack <- rbind(d, d_test)
library(ChiRP)
library(ChiRP)
n <- 200
set.seed(3)
# training
x<-seq(1,10*pi, length.out = n) # confounder
y<-rnorm( n = length(x), sin(.5*x), .07*x)
d <- data.frame(x=x, y=y)
d$x <- scale(d$x)
plot(d$x,d$y, pch=20)
d_test <- data.frame(x=seq(1.5,2,.01))
set.seed(1)
NDP_res<-NDPMix(d_train = d, d_test = d_test,
formula = y ~ x,
burnin=4000, iter = 5000,
phi_y = c(5,10), beta_var_scale = 10000,
init_k = 10, mu_scale = 2, tau_scale = .001)
par(mfrow=c(1,1))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
par(mfrow=c(1,1))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
set.seed(1)
NDP_res<-NDPMix(d_train = d, d_test = d_test,
formula = y ~ x,
burnin=4000, iter = 5000,
phi_y = c(5,10), beta_var_scale = 10000,
init_k = 10, mu_scale = .2, tau_scale = .001)
par(mfrow=c(1,1))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
set.seed(1)
NDP_res<-NDPMix(d_train = d, d_test = d_test,
formula = y ~ x,
burnin=5000, iter = 10000,
phi_y = c(5,10), beta_var_scale = 10000,
init_k = 10, mu_scale = .2, tau_scale = .001)
par(mfrow=c(1,1))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 9000:10000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
for(i in 4000:5000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
setwd("Dropbox/personal_site/")
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
log_post_beta <- function(beta, log_alpha, X, survt){ # shape
alpha <- exp(log_alpha)
mu <-  X %*% beta
lambda <- exp(-1*mu*alpha)
lik <- sum(dweibull( survt, shape = alpha, scale = lambda, log=T))
pr <- sum(dnorm(x = beta, mean = 0, sd = 100, log = T))
return(lik + pr)
}
log_post_alpha <- function(log_alpha, beta, X, survt){ # scale
alpha <- exp(log_alpha)
mu <-  X %*% beta
lambda <- exp(-1*mu*alpha)
lik <- sum(dweibull( survt, shape = alpha, scale = lambda, log=T))
pr <- dexp(x = alpha, rate = 1, log = T)
return(lik + pr)
}
metrop_hastings<-function(x_0, iter=1, log_post_density,
proposal_dist = function(x, prop_sigma){
MASS::mvrnorm(1, mu = x, Sigma = prop_sigma )
},
lower=-Inf, upper=Inf, prop_sigma,
... ){
for(i in 1:iter){
# draw from proposal distribution
x_star <- proposal_dist(x_0, prop_sigma)
# calculate ratio of conditional posterior densities
r_num <- do.call(log_post_density, c(list(x_star), list(...)) )
r_denom <- do.call(log_post_density, c(list(x_0), list(...)) )
r <- exp(r_num - r_denom)
rmin<-min(r,1)
if(is.na(rmin)) browser()
# accept / reject proposal
if(rbinom(1,1,rmin)==1){
x_0<-x_star
}
}
res<-list(x_0 = x_0, accept_prob = rmin )
return(res)
}
library(survival)
library(truncdist)
################################################################################
### 0 - Simulate Data
################################################################################
set.seed(1)
n <- 1000
A <- rbinom(n, 1, .5)
X <- model.matrix(~ A)
true_beta <- (1/2)*matrix(c(-1/3, 2), ncol=1)
true_mu <- X %*% true_beta
true_sigma <- 1
true_alpha <- 1/true_sigma
true_lambda <- exp(-1*true_mu*true_alpha)
# simulate censoring and survival times
survt = rweibull(n, shape=true_alpha, scale = true_lambda)
cent = rweibull(n, shape=true_alpha, scale = true_lambda)
## observed data:
#censoring indicator
delta <- cent < survt
survt[delta==1] <- cent[delta==1] # censor survival time.
# survt_all will combine observed and imputed survival times.
survt_all <- survt
# count number of missing/censored survival times
n_miss <- sum(delta) # number of censored subjects
row_miss <- c(1:n)[delta] # index for which rows are censored
iter <- 20000 # number of gibbs iterations
burnin <- 15000 # burn-in iterations
# shells for storing parameters
hazard_ratio <- numeric(iter - burnin)
# initial values
beta_shell <- matrix(c(0,0), ncol=1)
lalpha_shell <- c(0)
# proposal distribution for betas
prop_covar <- diag(c(.01,.01))
# plot stratified Kaplan-Meier
par(mfrow=c(1,1))
plot(survfit(Surv(survt, 1-delta) ~ A),conf.int = F, col=c('blue','red'),
xlab=c('Time'),ylab='Survival Probability',
main = 'Data augmentation with all subjects')
for(i in 2:iter){
## sample from posterior of parameters,
## conditional on observed and missing survival times
# metrop_hastings() is a custom function for generating a draw
# from conditional posterior of beta: log_post_beta
beta_shell <- metrop_hastings(x_0 = beta_shell,
iter = 1,
log_post_density = log_post_beta,
prop_sigma = prop_covar,
X=X, survt=survt_all,
log_alpha=lalpha_shell )$x_0
# sample from conditional posterior of alpha: log_post_alpha
lalpha_shell <- metrop_hastings(x_0 = lalpha_shell,
iter = 1,
log_post_density = log_post_alpha,
prop_sigma = matrix(.001),
X=X, survt=survt_all,
beta=beta_shell)$x_0
## sample from conditional posterior of missing survival times
mu_curr <-  X %*% beta_shell
alpha_curr <- exp(lalpha_shell)
for(m in row_miss){
lambda_curr <- exp(-1*mu_curr[m]*alpha_curr)
survt_all[m] <- rtrunc(1, spec = 'weibull',
a = survt[m],
shape =  alpha_curr,
scale =  lambda_curr)
}
if(i>burnin){
# store hazard ratio
hazard_ratio[i-burnin] <- exp(-beta_shell[2]/alpha_curr)
if(i>iter - 500){
# plot 500 posterior survival curve draws for treated and placebo
mu_trt <-  sum(beta_shell)
mu_pbo <-  beta_shell[1]
post_draw <- rweibull(n, shape = alpha_curr,
scale = exp(-1*mu_trt*alpha_curr)  )
post_ecdf <- ecdf(post_draw)
curve(1-post_ecdf(x), add=T, from=0, to=15, col='lightblue')
post_draw <- rweibull(n, shape = alpha_curr,
scale = exp(-1*mu_pbo*alpha_curr)  )
post_ecdf <- ecdf(post_draw)
curve(1-post_ecdf(x), add=T, from=0, to=15, col='darkgray')
}
}
}
# overlay KM curve and plot legend
lines(survfit(Surv(survt, 1-delta) ~ A),conf.int = T, col=c('black','blue'))
legend('topright',
legend = c('KM Curve and Intervals (TRT)',
'Posterior Survival Draws (TRT)',
'KM Curve and Intervals (PBO)',
'Posterior Survival Draws (PBO)'),
col=c('black','gray','blue','lightblue'),
lty=c(1,0,1,0), pch=c(NA,15,NA,15), bty='n')
mean(hazard_ratio)
quantile(hazard_ratio, probs=c(.025, .975))
exp(-true_beta[2]*true_alpha)
blogdown::build_site()
quantile(hazard_ratio, probs = c(.025, .975))
mean(hazard_ratio)
quantile(hazard_ratio, probs = c(.025, .975))
blogdown::build_site()
getwd()
blogdown:::new_post_addin()
blogdown::serve_site()
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = F, message = F, error = F, cache=T)
library(rstan)
library(survival)
plot(survfit(Surv(survt, 1-delta) ~ A ), col=c('black','blue'),
xlab='Time',ylab='Survival Probability', conf.int=T)
?plot.survfit
blogdown::build_site()
?sampling
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
ls
list.files()
blogdown:::new_post_addin()
blogdown::build_site()
blogdown::build_site()
