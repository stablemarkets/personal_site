<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>causal inference | </title>
    <link>https://stablemarkets.netlify.app/category/causal-inference/</link>
      <atom:link href="https://stablemarkets.netlify.app/category/causal-inference/index.xml" rel="self" type="application/rss+xml" />
    <description>causal inference</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 03 Dec 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://stablemarkets.netlify.app/media/icon_hu56437e0029043a6980b2632a303bfe7c_22443_512x512_fill_lanczos_center_3.png</url>
      <title>causal inference</title>
      <link>https://stablemarkets.netlify.app/category/causal-inference/</link>
    </image>
    
    <item>
      <title>Bayesian Sequential Decision-Making with Informative Timing</title>
      <link>https://stablemarkets.netlify.app/post/post6/bayeseq_aml/</link>
      <pubDate>Sat, 03 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://stablemarkets.netlify.app/post/post6/bayeseq_aml/</guid>
      <description>
&lt;script src=&#34;https://stablemarkets.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post is a brief summary of highlights from our &lt;a href=&#34;https://arxiv.org/abs/2211.16393&#34;&gt;recent working paper&lt;/a&gt; titled “Bayesian Semiparametric Model for Sequential Treatment Decisions with Informative Timing.” It’s part of a series of projects on developing robust Bayesian nonparametric models for sequential decision making in a variety of complex settings. In this case, we deal with a situation in which the decisions are informatively timed - with a motivating application in chemotherapy treatments for pediatric acute myeloid leukemia (AML).&lt;/p&gt;
&lt;p&gt;This is partially funded by a &lt;a href=&#34;https://www.pcori.org/research-results/2022/statistical-methods-optimizing-dynamic-patient-level-treatment-and-monitoring-strategies&#34;&gt;PCORI grant&lt;/a&gt; grant awarded earlier this year (2022).&lt;/p&gt;
&lt;div id=&#34;setting-and-problem&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Setting and Problem&lt;/h1&gt;
&lt;p&gt;Chemotherapy treatment in AML is not “one and done” but involves making a sequence of treatment decisions over time, with each subsequent treatment decision depending on how the patient has responded to previous trts and the evolution of their disease process. There are many chemo agents. This work focuses on understanding the effect of anthracyclines (ACT) in particular on survival. ACT is known to be effective in certain cases, but it can also lead to cardiotoxicity and subsequent early death.&lt;/p&gt;
&lt;p&gt;This presents clinicians with a risk-reward tradeoff - trting too aggressively or too conservatively with ACT may reduce survival. To help inform decisions, an echocardiogram is done to help decide if the heart is healthy enough to tolerate ACT. Clinicians follow various rules of thumb in practice. For instance: withholding ACT if a patient’s current ejection fraction (measured via echocardiogram) falls below some absolute threshold (eg 50%) or if it declines more than some relative (e.g. declines more than 20% from time of enrollment). Briefly, ejection fraction (EF) is the proportion of blood that is pumped out of the heart’s left ventricle during a beat. In healthy individuals, this is fairly high (from 50-75%) but can be lower among patients with cardiotoxicity. These treatment rules are “dynamic” in that ACT is decided based on evolving ejection fraction. This is in contrast to static rules such as “always trt with ACT”, “never trt with ACT” or “alternate ACT” - regardless of EF. The goal is to develop a strategy for estimating survival rates under various hypothetical ACT assignment rules. If we have such a method, we could evaluate the efficacy of the various rules of thumb employed in clinics and arrive at a more data-driven approach.&lt;/p&gt;
&lt;p&gt;Luckily, using data from the Phase III AAML1031 trial, we can estimate effects of such ACT trt strategies on survival. In the trial, patients move through a sequence of 4 chemo courses. Ahead of each course, an echo is conducted &amp;amp; used to decide ACT inclusion.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;challenges&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Challenges&lt;/h1&gt;
&lt;p&gt;There are many impediments to valid statistical estimation. 1) ACT is not randomized in the trial but informed by time-varying features such as EF. We need to adjust for such features to get an apples-to-apples comparison of different ACT rules. 2) Some patients die or drop out before ever completing the sequence. In the latter case, we are left with incomplete survival information. 3) Treatment courses are not initiated at pre-fixed times, but depending on when subjects recover from the previous chemotherapy course.&lt;/p&gt;
&lt;p&gt;This last point suggests that the waiting times between treatments are potential confounders (e.g. slower recovery after previous treatment may inform subsequent treatment and drive survival) - quite a unique type of time-varying confounding which requires modifications to the usual g-computation algorithm for sequential treatments&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-bayesian-semiparametric-method&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A Bayesian Semiparametric Method&lt;/h1&gt;
&lt;p&gt;We model the causal structure using a non-homogenous continuous-time transition process. After each course, patients can transition into a state of subsequent death or transition into a state of subsequent treatment - whichever comes first - in continuous-time. These process is characterized by a pair of transition probabilities: one pair for each treatment course. We use Bayesian semiparametric hazard models to estimate the transition probabilities at each stage as a function of features available at the start of this course.&lt;/p&gt;
&lt;p&gt;Causal effects of certain rules are computed by simulating from the transition process under a specified rule and computing the proportion of simulated subjects who survive past a certain time point (e.g. 3 years, if we want to compute 3-year survival).&lt;/p&gt;
&lt;p&gt;Here is a twitter thread with some more details and images:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Wanted to share some work I’ve been doing on semiparametric Bayesian methods for sequential decision making.&lt;br&gt;&lt;br&gt;This work is motivated by a need to understand the efficacy and toxicity of chemotherapy agents in pediatric acute myeloid leukemia (aml).&lt;a href=&#34;https://t.co/ivRMd6O7Vq&#34;&gt;https://t.co/ivRMd6O7Vq&lt;/a&gt;
&lt;/p&gt;
— Arman Oganisian (&lt;span class=&#34;citation&#34;&gt;@StableMarkets&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/StableMarkets/status/1598711965857087489?ref_src=twsrc%5Etfw&#34;&gt;December 2, 2022&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Sample versus Population ATE in Bayesian Caual Estimation</title>
      <link>https://stablemarkets.netlify.app/post/post5/tempered-mcmc/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://stablemarkets.netlify.app/post/post5/tempered-mcmc/</guid>
      <description>
&lt;script src=&#34;https://stablemarkets.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Writing up a quick post to clarify a point of common confusion when doing posterior inference for causal effects. All causal inference (regardless of statistical modeling paradigm in consideration) begins with expressing the target estimand in terms of unobservables (e.g. potential outcomes) and linking them to observed data with ``identification assumptions.’’ Two common estimands (which are often confused) are the population level average treatment effect (ATE) and the sample level ATE. These are two very different estimands and inferential procedures therefore differ for each. Yet, they seem to be confused with each other quite often. This post clarifies the distinction.&lt;/p&gt;
&lt;p&gt;Suppose we have a binary treatment &lt;span class=&#34;math inline&#34;&gt;\(A_i\in\{0,1\}\)&lt;/span&gt;, outcome &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt;, and a set of pre-treatment confounders &lt;span class=&#34;math inline&#34;&gt;\(L_i\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; independent subjects. Let the observed data be &lt;span class=&#34;math inline&#34;&gt;\(D = \{Y_i, A_i, L_i \}_{i=1}^n\)&lt;/span&gt;. Much of the following can be found in &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/full/10.1002/sim.8761&#34;&gt;Oganisian &amp;amp; Roy, 2020&lt;/a&gt; and &lt;a href=&#34;https://projecteuclid.org/journals/statistical-science/volume-33/issue-2/Causal-Inference-A-Missing-Data-Perspective/10.1214/18-STS645.full&#34;&gt;Ding and Li, 2018&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;the-population-level-ate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The population-level ATE&lt;/h2&gt;
&lt;p&gt;The population-level in potential outcome notation can be expressed as
&lt;span class=&#34;math display&#34;&gt;\[ \Psi = [Y^1 - Y^0] \]&lt;/span&gt;
Under certain identification assumptions, this is identified via the g-formula:
&lt;span class=&#34;math display&#34;&gt;\[ \Psi(\mu, P_L) = \int_{\mathcal{L}} \Big( \mu(1, l)- \mu(0, l)\Big) dP_L(l) \]&lt;/span&gt;
Where &lt;span class=&#34;math inline&#34;&gt;\(\mu(a, l) = E[Y\mid A=a, L=l]\)&lt;/span&gt; is the outcome regression function. Here the notation &lt;span class=&#34;math inline&#34;&gt;\(\Psi(\mu, P_L)\)&lt;/span&gt; makes it explicit that the causal estimand is a function of two unknowns: the unknown regression function and the unknown confounder distribution. If we have estimates of these objects, &lt;span class=&#34;math inline&#34;&gt;\(\hat \mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat P_L\)&lt;/span&gt;, frequentist inference can be done via a plug-in estimator
&lt;span class=&#34;math display&#34;&gt;\[ \hat\Psi(\hat \mu, \hat P_L) = \int_{\mathcal{L}} \Big( \hat\mu(1, l)- \hat\mu(0, l)\Big) d\hat P_L(l) \]&lt;/span&gt;
For example, if we could fit a standard GLM with some inverse-link function,&lt;span class=&#34;math inline&#34;&gt;\(g^{-1}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu(a, l) = g^{-1}(\hat \beta_0 + \hat \beta_1 A + \hat L&amp;#39;\beta_2)\)&lt;/span&gt;. Typically we use the empirical distribution for the confounder distribution estimate, &lt;span class=&#34;math inline&#34;&gt;\(\hat P_L(l) = \sum_{i=1}^n \frac{1}{n} I(L_i = l)\)&lt;/span&gt;. So we have
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\hat\Psi(\hat \mu, \hat P_L) &amp;amp; = \int_{\mathcal{L}} \Big( \hat\mu(1, l)- \hat\mu(0, l)\Big) d\hat P_L(l) \\
                              &amp;amp; = \sum_{i=1}^n \frac{1}{n} \Big( \hat\mu(1, L_i)- \hat\mu(0, L_i)\Big) \\
\end{align*}
\]&lt;/span&gt;
That is, we end up average the difference in the mean function,&lt;span class=&#34;math inline&#34;&gt;\(\hat\mu(a, l)\)&lt;/span&gt;, under both treatments over the empirical distribution of confounders. Typically bootstrap is used to compute interval estimates for the population ATE.&lt;/p&gt;
&lt;p&gt;Bayesian inference for this quantity is also straightforward: obtain the &lt;span class=&#34;math inline&#34;&gt;\(m^{th}\)&lt;/span&gt; posterior draw of the regression function &lt;span class=&#34;math inline&#34;&gt;\(\mu^{(m)}(a,l)\)&lt;/span&gt; under your favorite Bayesian model (a Generalized Linear Model, Gaussian process, Dirichlet Process, BART, etc). Then obtain the &lt;span class=&#34;math inline&#34;&gt;\(m^{th}\)&lt;/span&gt; posterior draw of the confounder distribution. It is common to use the ``Bayesian Bootstrap’’ for this - a Bayesian analogue of the empirical distribution: &lt;span class=&#34;math inline&#34;&gt;\(P_L^{(m)}(l) = \sum_{i=1}^n \gamma_i^{(m)} I(L_i = l)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\((\gamma_1^{(m)}, \gamma_2^{(m)}, \dots, \gamma_n^{(m)}) \sim Dir(1_n)\)&lt;/span&gt; are drawn froma Dirichlet Distribution. Then the posterior draw of the population-level ATE is
&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\Psi(\mu^{(m)}, P_L^{(m)}) &amp;amp; = \int_{\mathcal{L}} \Big(\mu^{(m)}(1, l)-\mu^{(m)}(0, l)\Big) d P_L^{(m)}(l) \\
                           &amp;amp; = \sum_{i=1}^n \gamma_i\Big(\mu^{(m)}(1, L_i)-\mu^{(m)}(0, L_i)\Big) \\
\end{align*}
\]&lt;/span&gt;
Again, we are taking a weighted average of the difference in the mean function draw, &lt;span class=&#34;math inline&#34;&gt;\(\mu^{(m)}(a, l)\)&lt;/span&gt;, under each intervention. Under the Bayesian bootstrap, the posterior expectation of each &lt;span class=&#34;math inline&#34;&gt;\(\gamma_i\)&lt;/span&gt; is 1/n - so you think can think of this as being centered around the empirical distribution. Doing this for &lt;span class=&#34;math inline&#34;&gt;\(m=1,2,\dots, M\)&lt;/span&gt; we get a set of posterior draws for the population ATE which can be used for point and interval estimation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-sample-level-ate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The sample-level ATE&lt;/h2&gt;
&lt;p&gt;The sample-level ATE is given by
&lt;span class=&#34;math display&#34;&gt;\[ \psi = \frac{1}{n} \sum_{i=1}^n (Y_i^1 - Y_i^0) \]&lt;/span&gt;
This is a very different estimand:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The uncertainty in the population-level ATE is due to uncertainty about the unknown regression function and confounder distribution.&lt;/li&gt;
&lt;li&gt;The uncertainty in the sample-level estimand is due to uncertainty about the unknown counterfactual. After all, under SUTVA for subject with assignment &lt;span class=&#34;math inline&#34;&gt;\(A_i\)&lt;/span&gt;, we only observe &lt;span class=&#34;math inline&#34;&gt;\(Y_i^{A_i}\)&lt;/span&gt; while &lt;span class=&#34;math inline&#34;&gt;\(Y_i^{1-A_i}\)&lt;/span&gt; is unobserved.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Bayesian solutions, of course, differ as well:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To estimate the population-level ATE, we must draw the unknonwn regression function and confounder distributions from the posterior, &lt;span class=&#34;math inline&#34;&gt;\(f(\mu, P_L \mid D)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;To estimate the sample-level ATE, we must draw the unknown counterfactual for each subject &lt;span class=&#34;math inline&#34;&gt;\(Y_i^{1-A_i}\)&lt;/span&gt; from the posterior &lt;span class=&#34;math inline&#34;&gt;\(f( \{ Y_i^{1-A_i} \}_{i=1}^n \mid D)\)&lt;/span&gt; .&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That last bullet is Bayesian inference for causal effects as originally described by Donald Rubin. Specifically, by Bayes’ rule
&lt;span class=&#34;math display&#34;&gt;\[ f( \{ Y_i^{1-A_i} \}_{i=1}^n \mid D) \propto f_A(A_i \mid L_i, Y_i^{A_i}, Y_i^{1-A_i} ) f_*(Y^A_i, Y_i^{1-A_i}\mid A_i, L_i) f_L(L_i) \]&lt;/span&gt;
if the usual ignorability holds (due to say a randomized treatment) - i.e. &lt;span class=&#34;math inline&#34;&gt;\(Y^1, Y^0 \perp A \mid L\)&lt;/span&gt; - the selection mechanism no longer depends on potential outcomes: &lt;span class=&#34;math display&#34;&gt;\[f_A(A_i \mid L_i, Y_i^{A_i}, Y_i^{1-A_i} ) = f_A(A_i \mid L_i )\]&lt;/span&gt;
and, along with &lt;span class=&#34;math inline&#34;&gt;\(f_L\)&lt;/span&gt; can be dropped while maintaining proportionality. But the crucial thing here is that the remaining joint distribution &lt;span class=&#34;math inline&#34;&gt;\(f_*(Y^A_i, Y_i^{1-A_i}\mid A_i, L_i)\)&lt;/span&gt; is  - we never observe both potential outcomes for subject &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. This complicates sample-level inference. We could still make inferences. For instance, by invoking de Finetti, we could model it as &lt;span class=&#34;math inline&#34;&gt;\(N_2(Y_i^{A_i}, Y_i^{1-A_i}\mid A_i, L_i; \eta, \Sigma ) p(\eta)p(\Sigma)\)&lt;/span&gt;. Where &lt;span class=&#34;math inline&#34;&gt;\(N_2\)&lt;/span&gt; indicates a bivariate normal distribution with mean vector &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; and 2x2 covariance matrix, &lt;span class=&#34;math inline&#34;&gt;\(\Sigma\)&lt;/span&gt;. But the off-diagonal terms of &lt;span class=&#34;math inline&#34;&gt;\(\Sigma\)&lt;/span&gt;, $ Cov( Y_i^{A_i}, Y_i^{1-A_i} ) $, cannot be learned from data. The posterior is still defined, but will be completely driven by the prior &lt;span class=&#34;math inline&#34;&gt;\(p(\Sigma)\)&lt;/span&gt;. Thus, the sample-level effect is significantly more complicated .&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
