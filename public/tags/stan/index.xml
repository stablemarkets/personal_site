<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stan on </title>
    <link>/tags/stan/</link>
    <description>Recent content in Stan on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 09 Mar 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/stan/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Specifying Accelerated Failure Time Models in STAN</title>
      <link>/post/post2/specifying-accelerated-failure-time-models-in-stan/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/post2/specifying-accelerated-failure-time-models-in-stan/</guid>
      <description>


&lt;p&gt;This post is an add-on to my &lt;a href=&#34;https://stablemarkets.netlify.com/post/post1/bayesian-survival-analysis-with-data-augmentation/&#34;&gt;previous post&lt;/a&gt; about augmented gibbs sampling for censored survival times. If you’re not a complete maniac like me, then you probably don’t want to code your own sampler from scratch like I did in that previous post. Luckily you don’t have to because you can easily specify that same model in &lt;a href=&#34;https://mc-stan.org/users/interfaces/rstan&#34;&gt;Stan&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s start with simulating some randomly censored data from a Weibull model. In this case, we just include a binary indicator and are interested in characterizing survival between these two groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

n &amp;lt;- 1000

# simulate covariates (just a binary treatment indicator)
A &amp;lt;- rbinom(n, 1, .5)
X &amp;lt;- model.matrix(~ A)

# true parameters
true_beta &amp;lt;- (1/2)*matrix(c(-1/3, 2), ncol=1)
true_mu &amp;lt;- X %*% true_beta

true_sigma &amp;lt;- 1

true_alpha &amp;lt;- 1/true_sigma
true_lambda &amp;lt;- exp(-1*true_mu*true_alpha)

# simulate censoring and survival times
survt = rweibull(n, shape=true_alpha, scale = true_lambda) 
cent = rweibull(n, shape=true_alpha, scale = true_lambda)

## observed data:
#censoring indicator
delta &amp;lt;- cent &amp;lt; survt
survt[delta==1] &amp;lt;- cent[delta==1] # censor survival time.

# count number of missing/censored survival times
n_miss &amp;lt;- sum(delta)

d_list &amp;lt;- list(N_m = n_miss, N_o = n - n_miss, P=2, # number of betas
               # data for censored subjects
               y_m=survt[delta==1], X_m=X[delta==1,],
               # data for uncensored subjects
               y_o=survt[delta==0], X_o=X[delta==0,])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The list &lt;code&gt;d_list&lt;/code&gt; is what we’ll eventually feed to Stan. Below is the Stan model for Weibull distributed survival times. Note in the transformed parameters block we specify the canonical accelerated failure time (AFT) parameterization - modeling the scale as a function of the shape parameter, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, and covariates.&lt;/p&gt;
&lt;p&gt;In the model block, we specify the likelihood as the Weibull density for uncensored subjects, and then augment the likelihood with evaluations from the Weibull survival function (&lt;code&gt;_lccdf&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;The generated quantities block transforms the parameters to get posterior draws of the hazard ratio (as specified in my &lt;a href=&#34;https://stablemarkets.netlify.com/post/post1/bayesian-survival-analysis-with-data-augmentation/&#34;&gt;previous post&lt;/a&gt; ) as well as posterior draws of the survival function.&lt;/p&gt;
&lt;pre class=&#34;stan&#34;&gt;&lt;code&gt;data {
  int&amp;lt;lower=0&amp;gt; P; // number of beta parameters
  
  // data for censored subjects
  int&amp;lt;lower=0&amp;gt; N_m;
  matrix[N_m,P] X_m;
  vector[N_m] y_m;
  
  // data for observed subjects
  int&amp;lt;lower=0&amp;gt; N_o;
  matrix[N_o,P] X_o;
  real y_o[N_o];
}

parameters {
  vector[P] beta;                
  real&amp;lt;lower=0&amp;gt; alpha; // Weibull Shape      
}

transformed parameters{
  // model Weibull rate as function of covariates
  vector[N_m] lambda_m;
  vector[N_o] lambda_o;
  
  // standard weibull AFT re-parameterization
  lambda_m = exp((X_m*beta)*alpha);
  lambda_o = exp((X_o*beta)*alpha);
}

model {
  beta ~ normal(0, 100);
  alpha ~ exponential(1);
  
  // evaluate likelihood for censored and uncensored subjects
  target += weibull_lpdf(y_o | alpha, lambda_o);
  target += weibull_lccdf(y_m | alpha, lambda_m);
}


// generate posterior quantities of interest
generated quantities{
  vector[1000] post_pred_trt;
  vector[1000] post_pred_pbo;
  real lambda_trt; 
  real lambda_pbo; 
  real hazard_ratio;
  
  // generate hazard ratio
  lambda_trt = exp((beta[1] + beta[2])*alpha ) ;
  lambda_pbo = exp((beta[1])*alpha ) ;
  
  hazard_ratio = exp(beta[2]*alpha ) ;
  
  // generate survival times (for plotting survival curves)
  for(i in 1:1000){
    post_pred_trt[i] = weibull_rng(alpha,  lambda_trt);
    post_pred_pbo[i] = weibull_rng(alpha,  lambda_pbo);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Stan model specified above is stored in an object called &lt;code&gt;weibull_mod&lt;/code&gt;, which is called below in &lt;code&gt;sampling()&lt;/code&gt;. The code below samples from the posterior and outputs posterior draws of the hazard and predicted survival times.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weibull_fit &amp;lt;- sampling(weibull_mod,
                data = d_list, 
                chains = 1, iter=20000, warmup=19000, save_warmup=F,
                pars= c(&amp;#39;hazard_ratio&amp;#39;,&amp;#39;post_pred_trt&amp;#39;,&amp;#39;post_pred_pbo&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;80acc0f9293b946800a710dd7f5e211c&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0.000146 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.46 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:     1 / 20000 [  0%]  (Warmup)
## Chain 1: Iteration:  2000 / 20000 [ 10%]  (Warmup)
## Chain 1: Iteration:  4000 / 20000 [ 20%]  (Warmup)
## Chain 1: Iteration:  6000 / 20000 [ 30%]  (Warmup)
## Chain 1: Iteration:  8000 / 20000 [ 40%]  (Warmup)
## Chain 1: Iteration: 10000 / 20000 [ 50%]  (Warmup)
## Chain 1: Iteration: 12000 / 20000 [ 60%]  (Warmup)
## Chain 1: Iteration: 14000 / 20000 [ 70%]  (Warmup)
## Chain 1: Iteration: 16000 / 20000 [ 80%]  (Warmup)
## Chain 1: Iteration: 18000 / 20000 [ 90%]  (Warmup)
## Chain 1: Iteration: 19001 / 20000 [ 95%]  (Sampling)
## Chain 1: Iteration: 20000 / 20000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 9.15608 seconds (Warm-up)
## Chain 1:                0.737352 seconds (Sampling)
## Chain 1:                9.89344 seconds (Total)
## Chain 1:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_draws&amp;lt;-extract(weibull_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below we plot posterior distribution of the hazard ratio. The red line indicates the true value under which we generated the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(post_draws$hazard_ratio,
     xlab=&amp;#39;Hazard Ratio&amp;#39;, main=&amp;#39;Hazard Ratio Posterior Distribution&amp;#39;)
abline(v=exp(-1*true_beta[2,1]*true_alpha), col=&amp;#39;red&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/post2/2019-03-09-specifying-accelerated-failure-time-models-in-stan_files/figure-html/plot_hazard_ratio-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(post_draws$hazard_ratio)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3635223&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(post_draws$hazard_ratio, probs = c(.025, .975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      2.5%     97.5% 
## 0.2989080 0.4399663&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below we plot the survival functions. Note these results are very similar to the augmented sampler coded in the previous post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(survfit(Surv(survt, 1-delta) ~ A ), col=c(&amp;#39;black&amp;#39;,&amp;#39;blue&amp;#39;),
     xlab=&amp;#39;Time&amp;#39;,ylab=&amp;#39;Survival Probability&amp;#39;, conf.int=T)

for(i in 1:1000){
  trt_ecdf &amp;lt;- ecdf(post_draws$post_pred_trt[i,])
  curve(1 - trt_ecdf(x), from = 0, to=4, add=T, col=&amp;#39;gray&amp;#39;)
  
  pbo_ecdf &amp;lt;- ecdf(post_draws$post_pred_pbo[i,])
  curve(1 - pbo_ecdf(x), from = 0, to=4, add=T, col=&amp;#39;lightblue&amp;#39;)
}

lines(survfit(Surv(survt, 1-delta) ~ A ), col=c(&amp;#39;black&amp;#39;,&amp;#39;blue&amp;#39;), add=T,
      conf.int=T)

legend(&amp;#39;topright&amp;#39;, 
       legend = c(&amp;#39;KM Curve and Intervals (TRT)&amp;#39;,
                  &amp;#39;Posterior Survival Draws (TRT)&amp;#39;,
                  &amp;#39;KM Curve and Intervals (PBO)&amp;#39;,
                  &amp;#39;Posterior Survival Draws (PBO)&amp;#39;),
       col=c(&amp;#39;black&amp;#39;,&amp;#39;gray&amp;#39;,&amp;#39;blue&amp;#39;,&amp;#39;lightblue&amp;#39;), 
       lty=c(1,0,1,0), pch=c(NA,15,NA,15), bty=&amp;#39;n&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/post2/2019-03-09-specifying-accelerated-failure-time-models-in-stan_files/figure-html/plot_survival-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
