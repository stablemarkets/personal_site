[{"authors":["admin"],"categories":null,"content":"I’m a biostatistics PhD candidate at the University of Pennsylvania, an Associate Fellow at the LDI, and a member of the Center for Causal Inference. My research centers around developing Bayesian nonparametric methods with applications to health economics, prediction, and causal inference problems. Before Penn, I was a Senior Analyst at Analysis Group\u0026rsquo;s health economics and outcomes research (HEOR) group.\nI blog about statistics, bayesian methods, computation/MCMC, visualization, and other things I happen to stumble upon during research.\nMy blog posts are syndicated on R-bloggers.\n","date":1551886505,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1551886505,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I’m a biostatistics PhD candidate at the University of Pennsylvania, an Associate Fellow at the LDI, and a member of the Center for Causal Inference. My research centers around developing Bayesian nonparametric methods with applications to health economics, prediction, and causal inference problems. Before Penn, I was a Senior Analyst at Analysis Group\u0026rsquo;s health economics and outcomes research (HEOR) group.\nI blog about statistics, bayesian methods, computation/MCMC, visualization, and other things I happen to stumble upon during research.","tags":null,"title":"Arman Oganisian","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536465600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1551886505,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":["Bayesian","Survival Analysis","MCMC"],"content":"  Motivation Model Set Up Data Augmentation Metropolis-in-Gibbs Sampler Simulation Example in R   Motivation When dealing with time-to-event data, right-censoring is a common occurance. Although most are familiar with likelihood construction under right-censoring (and corresponding frequentist estimation), there’s very little available online about Bayesian approaches even for fully parametric models. Here I’ll briefly outline a Bayesian estimation procedure for a Weibull model with right-censoring. The estimation procedure is MCMC based using a data augmentation approach.\nAs with most of my posts, all MCMC is coded from scratch. It helps me and it helps readers understand the underlying algorithm - an intuition that is more difficult to get if you’re just specifying the model in Stan.\n Model Set Up Suppose we observe \\(i=1,\\dots, r\\) survival times, \\(T^o_i\\). Survival times past the end of our study (at time \\(\\tau\\)) are censored for subjects \\(i=r+1, \\dots, n\\). We know that the survival times for these subjects are greater than \\(\\tau\\), but that is all. Say we also have some \\(p\\times 1\\) covariate vector, \\(x_i\\). Finally, we have indicator of whether survival time is observed \\(\\delta_{1:n}\\) for each subject. A parametric approach follows by assuming a model for \\(T\\), we choose the Weibull\n\\[ T^o_i \\sim Weibull(\\alpha, \\lambda_i) \\] Where \\(\\alpha\\) is the shape parameter and \\(\\lambda_i\\) is a subject-specific scale. An Accelerated Failure Time model (AFT) follows from modeling a reparameterization of the scale function \\(\\lambda_i = exp(-\\mu_i\\alpha)\\), where \\(\\mu_i = x_i^T\\beta\\).\nWe’ll consider the setting where we regress on a binary treatment indicator, \\(\\mu_i = \\beta_0 + \\beta_1A\\) where \\(A=1\\) indicates treated and \\(A=0\\) indicates untreated/placebo. This is a funky reparameterization, but it yields intuitive interpretations for \\(\\beta_1\\) in terms of the Weibull’s hazard function, \\(h(t|\\beta,x, \\alpha) = \\lambda_i\\alpha x^{\\alpha-1}\\). Substituting \\(\\lambda_i\\), we seethe hazard for treated subjects is \\(h(t|A=1) = e^{-(\\beta_0 + \\beta_1)/\\alpha}\\alpha t^{\\alpha-1}\\) and for untreated subjects it is \\(h(t|A=1) = e^{-(\\beta_0)/\\alpha}\\alpha t^{\\alpha-1}\\). The hazard ratio is,\n\\[HR = \\frac{h(t|A=1) }{h(t|A=0)} = e^{-\\beta_1/\\alpha} \\] If \\(HR=.5\\), then the hazard of death, for example, at time \\(t\\) is \\(50\\%\\) lower in the treated group, relative to the untreated.\nFrom a Bayesian point of view, we are interested in the posterior \\(p(\\beta, \\alpha | T^o_{1:r} , \\delta_{1:n}, \\tau)\\). Once we have this, we can get a whole posterior distribution for the survival function itself - as well as any quantity derived from it. For example, posterior mean and credible intervals for \\(HR\\) (just a function of \\(\\beta_1\\) and \\(\\alpha\\)). We can also get posterior survival curve estimates for each treatment group. For the Weibull, the survival curve is given by \\(S(t|\\beta,\\alpha, A) = exp(-\\lambda t^\\alpha)\\) - again just a function of \\(\\beta_1\\) and \\(\\alpha\\).\n Data Augmentation We’ll first look at the joint data distribution (the likelihood) for this problem. The central idea is to view the survival times for the \\(n-r\\) censored subjects as missing data, \\(T^m_{r+1:n}\\). We refer to the full data as \\(T_{i=1:n} = (T_{i:r}^o, T_{r+1:n}^m)\\). Now we construct a complete-data (augmented) likelihood with these values. The observed likelihood and complete-data likelihood are related by\n\\[ \\begin{aligned} p(T^o_{1:r}, \\delta_{1:n}| \\tau, \\beta, \\alpha) \u0026amp; = \\int p(T_{1:n}, \\delta_{1:n} | \\tau, \\beta, \\alpha) \\ dT^m_{r+1:n} \\\\ \u0026amp; = \\int p(\\delta_{1:n} | T_{1:n}, \\tau, \\beta, \\alpha) \\ p(T_{1:n} | \\tau, \\beta, \\alpha) \\ dT^m_{r+1:n} \\end{aligned} \\] Now in this ideal, complete-data setting, we observe patients with either \\(\\delta_i = 1 \\ \\cap \\ T_i \u0026gt; \\tau\\) or with \\(\\delta_i = 0 \\ \\cap \\ T_i \u0026lt; \\tau\\). That is, \\(p(\\delta_{i} | T_i, \\tau, \\beta, \\alpha)=1\\) if either of these conditions hold and \\(0\\) otherwise.\nWe also assume that subjects are independent so that \\(p(T_{i=1:n} | \\tau, \\beta, \\alpha) = p(T^o_{1:r}| \\tau, \\beta, \\alpha)p( T^m_{r+1:n} | \\tau, \\beta, \\alpha)\\). So the likelihood simplifies to: \\[ \\begin{aligned} p(T^o_{1:r}, \\delta_{1:n}| \\tau, \\beta, \\alpha) \u0026amp; = \\prod_{i=1}^n\\int p(\\delta_{i} | T_{i}, \\tau, \\beta, \\alpha) \\ p(T_{i} | \\tau, \\beta, \\alpha) \\ dT^m_{r+1:n} \\\\ \u0026amp; = \\prod_{i| \\delta_i=0} p(T_{i}^o | \\tau, \\beta, \\alpha) \\prod_{i| \\delta_i=1} \\int p(\\delta_{i} | T^m_{i}, \\tau, \\beta, \\alpha) \\ p(T_{i}^m | \\tau, \\beta, \\alpha) \\ dT^m_{i} \\\\ \u0026amp; = \\prod_{i| \\delta_i=0} p(T_{i}^o | \\tau, \\beta, \\alpha) \\prod_{i| \\delta_i=1} \\int I(T_i^m \u0026gt; \\tau) \\ p(T_{i}^m | \\tau, \\beta, \\alpha) \\ dT^m_{i} \\\\ \u0026amp; = \\prod_{i| \\delta_i=0} p(T_{i}^o | \\tau, \\beta, \\alpha) \\prod_{i| \\delta_i=1} \\int_\\tau^\\infty \\ p(T_{i}^m | \\tau, \\beta, \\alpha) \\ dT^m_{i} \\\\ \\end{aligned} \\] The first line follows by independence of observations. The second line follows by separating censored and uncensored subjects. \\(p(\\delta_i | -)=1\\) for all uncensored subjects, but \\(p(\\delta_i | -)=1\\) for censored subjects only when \\(T_i^m \\in (0, \\infty)\\). Otherwise, the integrand is 0. Therefore, in the fourth line we only need to integrate of the region where the integrand is non-zero.\nNow the integral is over the region \\(T_i^m \\in (0, \\infty)\\). But in this region \\(p(\\delta_{i} | T^m_{i}, \\tau, \\beta, \\alpha)=1\\) only when \\(T_i^m \u0026gt;\\tau\\).\nThis is the usual likelihood for frequentist survival models: uncensored subjects contribute to the likelihood via the density while censored subjects contribute to the likelihood via the survival function \\(\\int_\\tau^\\infty \\ p(T_{i}^m | \\tau, \\beta, \\alpha) \\ dT^m_{i}\\). Functions for this integral exist in for most basic distributions in R. For our Weibull model, it is 1-pweibull(). We would simply place priors on \\(\\beta\\) and \\(\\alpha\\), then sample from the posterior using MCMC.\nBut what if this integral was too hard to evaluate (as it may be for more complicated censoring mechanisms) and the complete data likelihood given below is easier?\n\\[ \\begin{aligned} p(T^o_{1:r}, T^m_{r+1:n}, \\delta_{1:n}| \\tau, \\beta, \\alpha) \u0026amp; = \\prod_{i| \\delta_i=0} p(T_{i}^o | \\tau, \\beta, \\alpha) \\prod_{i| \\delta_i=1} I(T_i^m \u0026gt; \\tau)\\ p(T_{i}^m | \\tau, \\beta, \\alpha)\\\\ \\end{aligned} \\] Then we can design a Gibbs sampler around this complete data likelihood.\n Metropolis-in-Gibbs Sampler The target posterior of interest is \\[p(\\beta, \\alpha, T_{r+1:n}^m | T^o_{1:r}, \\delta_{1:n}) = p(\\beta, \\alpha | T_{r+1:n}^m, T^o_{1:r}, \\delta_{1:n}) \\ p(T_{r+1:n}^m | \\beta, \\alpha, T^o_{1:r}, \\delta_{1:n})\\] Where each conditional posterior is known up to a proportionality constant. With a joint prior \\(p(\\beta, \\alpha)\\) specified, we have\n\\[ \\begin{aligned} p(\\beta, \\alpha | T_{r+1:n}^m, T^o_{1:r}, \\delta_{1:n}) \u0026amp; \\propto \\prod_{i| \\delta_i=0} p(T_{i}^o | \\tau, \\beta, \\alpha) \\prod_{i| \\delta_i=1} I(T_i^m \u0026gt; \\tau)\\ p(T_{i}^m | \\tau, \\beta, \\alpha) \\\\ \u0026amp; \\propto p(\\beta, \\alpha) \\prod_{i=1}^n p(T_{i}| \\tau, \\beta, \\alpha) \\\\ \\end{aligned} \\] Note here that \\(p(T_{i}| \\tau, \\beta, \\alpha)\\) is the assumed Weibull density. We can use a Metropolis step to sample \\((\\beta, \\alpha)\\) from this distribution.\nThe second conditional posterior is \\[\\begin{equation} \\begin{aligned} p(T_{r+1:n}^m | \\beta, \\alpha, T^o_{1:r}, \\delta_{1:n}) \\propto \\prod_{i| \\delta_i=1} I(T_i^m \u0026gt; \\tau)\\ p(T_{i}^m | \\tau, \\beta, \\alpha) \\end{aligned} \\end{equation}\\] This is a truncated Weibull distribution (truncated at the bottom by \\(\\tau\\)). We can also sample from this using a Metropolis step.\nThe Gibbs sampler alternates between sampling from these two conditionals:\nGiven parameters \\((\\beta, \\alpha)\\), impute \\(T^m_i\\) by drawing from \\(p(T_{r+1:n}^m | \\beta, \\alpha, T^o_{1:r}, \\delta_{1:n})\\), for each \\(i=r+1,\\dots, n\\). Combine these imputed values, \\(T^m_{r+1:n}\\), with observed data \\(T_{1:n}^o\\), and update the parameters \\((\\beta, \\alpha)\\) from \\(p(\\beta, \\alpha | T_{r+1:n}^m, T^o_{1:r}, \\delta_{1:n})\\).  As the parameter estimates update, the imputations get better. As the imputations get better, the parameter estimates improve. Over time the process yields draws from the joint posterior \\(p(\\beta, \\alpha, T_{r+1:n}^m | T^o_{1:r}, \\delta_{1:n})\\)\nWe retain the sample of \\((\\beta, \\alpha)\\) for inference and toss samples of \\(T^m\\).\n Simulation Example in R All of the code implementing the augmented sampler (from scratch!) can be found on my GitHub. Basically I simulate a data set with a binary treatment indicator for 1,000 subjects with censoring and survival times independently drawn from a Weibull. \\\nFor the \\(\\beta\\) vector, I use independent \\(N(0,sd=100)\\) priors. For the shape parameter, I use an \\(Exp(1)\\) prior. I run a single MCMC chain for 20,000 iterations and toss the first 15,000 out as burn-in.\nHere is the estimated survival function for each treatment group. Overlayed are the non-parametric estimates from a stratified Kaplan-Meier (KM) estimator. Note the parametric model is correctly specified here, so it does just as well as the KM in terms of estimating the mean curve. But the parametric model provides a less noisy fit - notice the credible bands are narrower at later time points when the at-risk counts get low in each treatment arm.\nThat’s just a helpful reminder of the efficiency gains parametric models have over nonparametric ones (when they’re correctly specified. Let’s take a look at the posterior distribution of the hazard ratio. The true value is indicated by the red line.\nWe could have run this thing for longer (and with multiple chains with different starting values). But I think this gets the point across. The posterior mean and \\(95\\%\\) credible interval are \\(.32 \\ (.24-.41)\\). The true value is \\(.38\\). Not too bad, but not too good either. Remember this is only a single simulated dataset.\n ","date":1551830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551830400,"objectID":"1ed5a14dc1eb43b855339c99bfc17580","permalink":"/post/post1/bayesian-survival-analysis-with-data-augmentation/","publishdate":"2019-03-06T00:00:00Z","relpermalink":"/post/post1/bayesian-survival-analysis-with-data-augmentation/","section":"post","summary":"Motivation Model Set Up Data Augmentation Metropolis-in-Gibbs Sampler Simulation Example in R   Motivation When dealing with time-to-event data, right-censoring is a common occurance. Although most are familiar with likelihood construction under right-censoring (and corresponding frequentist estimation), there’s very little available online about Bayesian approaches even for fully parametric models. Here I’ll briefly outline a Bayesian estimation procedure for a Weibull model with right-censoring. The estimation procedure is MCMC based using a data augmentation approach.","tags":["R","Bayesian"],"title":"Bayesian Survival Analysis with Data Augmentation","type":"post"},{"authors":["**A. Oganisian**","Nandita Mitra","Jason Roy"],"categories":null,"content":"","date":1548997200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551886505,"objectID":"6e0ffb78f851063e9879b31a13d0ea87","permalink":"/publication/zdp/","publishdate":"2019-02-01T00:00:00-05:00","relpermalink":"/publication/zdp/","section":"publication","summary":"","tags":[],"title":"Bayesian Nonparametric Method for Zero-Inflated Outcomes: Prediction, Clustering, and Causal Inference","type":"publication"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551886505,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["Rebecca A. Hubbard","Jing Huang","Joanna Harton","**A. Oganisian**","Grace Choi","Levon Utidjian","Ihuoma Eneli","L. Charles Bailey","Yong Chen"],"categories":null,"content":"","date":1535947200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551886505,"objectID":"ada066a1cbb5930c0d855c946c9e9e37","permalink":"/publication/bayes_latent_phenotype/","publishdate":"2018-09-03T00:00:00-04:00","relpermalink":"/publication/bayes_latent_phenotype/","section":"publication","summary":"","tags":[],"title":"A Bayesian latent class approach for EHR‐based phenotyping","type":"publication"},{"authors":["Arman Oganisian"],"categories":null,"content":"","date":1532977500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551886505,"objectID":"4e1d43d1c2ed5b55119cc8b6d77030a5","permalink":"/talk/jsm2017/","publishdate":"2018-07-30T15:05:00-04:00","relpermalink":"/talk/jsm2017/","section":"talk","summary":"","tags":[],"title":"A Bayesian Nonparametric Method for Zero-Inflated Data with Applications to Medical Costs","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551886505,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551886505,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551886505,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]