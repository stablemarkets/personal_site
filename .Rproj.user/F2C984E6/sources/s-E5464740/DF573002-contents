---
title: Bayesian Survival Analysis with Data Augmentation
author: Arman Oganisian
date: '2019-03-06'
slug: bayesian-survival-analysis-with-data-augmentation
categories:
  - Bayesian
  - Survival Analysis
  - MCMC
tags:
  - R
  - Bayesian
image:
  caption: ''
  focal_point: ''
output:
  blogdown::html_page:
    toc: true
---

## Motivation
When dealing with time-to-event data, right-censoring is a common occurance. Although most are familiar with likelihood construction under right-censoring (and corresponding frequentist estimation), there's very little available online about Bayesian approaches even for fully parametric models. Here I'll briefly outline a Bayesian estimation procedure for a Weibull model with right-censoring. The estimation procedure is MCMC based using a data augmentation approach.

As with most of my posts, all MCMC is coded from scratch. It helps me and it helps readers understand the underlying algorithm - an intuition that is more difficult to get if you're just specifying the model in Stan.

## Model Set Up
Suppose we observe $i=1,\dots, r$ survival times, $T^o_i$. Survival times past the end of our study (at time $\tau$) are censored for subjects $i=r+1, \dots, n$. We know that the survival times for these subjects are greater than $\tau$, but that is all. Say we also have some $p\times 1$ covariate vector, $x_i$ and our task is to make inference about the survival function $P(T \geq t)$. Finally, we have indicator of whether survival time is observed $\delta_{1:n}$ for each subject. A parametric approach follows by assuming a model for $T$, we choose the Weibull

$$ T^o_i \sim Weibull(a_i, b) $$
Where $a$ is the shape parameter and $b$ is the scale. We model the shape parameter as a function of covariates $a_i = exp(x_i^T \beta)$.

In this parametric setting, the target of interest (the survival function) is determined by the Weibull parameters, $P(T>t| a_i, b)$ - which we'll need to estimate.

From a Bayesian point of view, we are interested in the posterior $p(\beta, b | T^o_{1:r} ,  \tau)$. Once we have this, we can get a whole posterior distribution for the survival function itself - as well as any quantity derived from it (e.g. mean survival time, hazard, etc).

## Data Augmentation
We'll first look at the joint data distribution (the likelihood) for this problem. The central idea is to view the survival times for the $n-r$ censored subjects as missing data, $T^m_{r+1:n}$. We refer to the full data as $T_{i=1:n} = (T_{i:r}^o, T_{r+1:n}^m)$. Now we construct a complete-data (augmented) likelihood with these values. The observed likelihood and complete-data likelihood are related by

$$
\begin{aligned}
 p(T^o_{1:r}, \delta_{1:n}| \tau, \beta, b) & = \int p(T_{1:n}, \delta_{1:n} | \tau, \beta, b) \ dT^m_{r+1:n} \\
  & = \int p(\delta_{1:n} | T_{1:n}, \tau, \beta, b) \ p(T_{1:n} | \tau, \beta, b) \ dT^m_{r+1:n}
\end{aligned}
$$
Now in this ideal, complete-data setting, we observe patients with either $\delta_i = 1 \ \cap \ T_i > \tau$ or with $\delta_i = 0 \ \cap \ T_i < \tau$. That is, $p(\delta_{i} | T_i, \tau, \beta, b)=1$ if either of these conditions hold and $0$ otherwise.

We also assume that subjects are independent so that $p(T_{i=1:n} | \tau, \beta, b) = p(T^o_{1:r}| \tau, \beta, b)p( T^m_{r+1:n} | \tau, \beta, b)$. So the likelihood simplifies to:
$$
\begin{aligned}
 p(T^o_{1:r}, \delta_{1:n}| \tau, \beta, b) & = \prod_{i=1}^n\int p(\delta_{i} | T_{i}, \tau, \beta, b) \ p(T_{i} | \tau, \beta, b) \ dT^m_{r+1:n} \\
 & = \prod_{i| \delta_i=0} p(T_{i}^o | \tau, \beta, b) \prod_{i| \delta_i=1} \int p(\delta_{i} | T^m_{i}, \tau, \beta, b) \ p(T_{i}^m | \tau, \beta, b) \ dT^m_{i} \\
& = \prod_{i| \delta_i=0} p(T_{i}^o | \tau, \beta, b) \prod_{i| \delta_i=1} \int I(T_i^m > \tau) \ p(T_{i}^m | \tau, \beta, b) \ dT^m_{i} \\
& = \prod_{i| \delta_i=0} p(T_{i}^o | \tau, \beta, b) \prod_{i| \delta_i=1} \int_\tau^\infty \ p(T_{i}^m | \tau, \beta, b) \ dT^m_{i} \\
\end{aligned}
$$
The first line follows by independence of observations. The second line follows by separating censored and uncensored subjects. $p(\delta_i | -)=1$ for all uncensored subjects, but $p(\delta_i | -)=1$ for censored subjects only when $T_i^m \in (0, \infty)$. Otherwise, the integrand is 0. Therefore, in the fourth line we only need to integrate of the region where the integrand is non-zero. 

Now the integral is over the region $T_i^m \in (0, \infty)$. But in this region $p(\delta_{i} | T^m_{i}, \tau, \beta, b)=1$ only when $T_i^m >\tau$. 

This is the usual likelihood for frequentist survival models: uncensored subjects contribute to the likelihood via the density while censored subjects contribute to the likelihood via the survival function $\int_\tau^\infty \ p(T_{i}^m | \tau, \beta, b) \ dT^m_{i}$. Functions for this integral exist in for most basic distributions in `R`. For our Weibull model, it is `1-pweibull()`. We would simply place priors on $\beta$ and $b$, then sample from the posterior using MCMC. 

But what if this integral was too hard to evaluate (as it may be for more complicated censoring mechanisms) and the complete data likelihood given below is easier?

$$
\begin{aligned}
 p(T^o_{1:r}, T^m_{r+1:n}, \delta_{1:n}| \tau, \beta, b) & = \prod_{i| \delta_i=0} p(T_{i}^o | \tau, \beta, b) \prod_{i| \delta_i=1} I(T_i^m > \tau)\ p(T_{i}^m | \tau, \beta, b)\\
\end{aligned}
$$
Then we can design a Gibbs sampler around this complete data likelihood.

## Metropolis-in-Gibbs Sampler
The target posterior of interest is 
$$p(\beta, b, T_{r+1:n}^m | T^o_{1:r}, \delta_{1:n}) = p(\beta, b | T_{r+1:n}^m, T^o_{1:r}, \delta_{1:n}) \ p(T_{r+1:n}^m | \beta, b, T^o_{1:r}, \delta_{1:n})$$
Where each conditional posterior is known up to a proportionality constant. With a joint prior $p(\beta, b)$ specified, we have

$$
\begin{aligned}
p(\beta, b | T_{r+1:n}^m, T^o_{1:r}, \delta_{1:n}) & \propto \prod_{i| \delta_i=0} p(T_{i}^o | \tau, \beta, b) \prod_{i| \delta_i=1} I(T_i^m > \tau)\ p(T_{i}^m | \tau, \beta, b)  \\
& \propto p(\beta, b) \prod_{i=1}^n p(T_{i}| \tau, \beta, b) \\
\end{aligned}
$$
Note here that $p(T_{i}| \tau, \beta, b)$ is the assumed Weibull density. We can use a Metropolis step to sample $(\beta, b)$ from this distribution. 

The second conditional posterior is 
\begin{equation}
\begin{aligned}
p(T_{r+1:n}^m | \beta, b, T^o_{1:r}, \delta_{1:n}) \propto \prod_{i| \delta_i=1} I(T_i^m > \tau)\ p(T_{i}^m | \tau, \beta, b)
\end{aligned}
\end{equation}
This is a truncated Weibull distribution (truncated at the bottom by $\tau$). We can also sample from this using a Metropolis step.


The Gibbs sampler alternates between sampling from these two conditionals:

1. Given parameters $(\beta, b)$, impute $T^m_i$ by drawing from $p(T_{r+1:n}^m | \beta, b, T^o_{1:r}, \delta_{1:n})$, for each $i=r+1,\dots, n$.
2. Combine these imputed values, $T^m_{r+1:n}$, with observed data $T_{1:n}^o$, and update the parameters $(\beta, b)$ from $p(\beta, b | T_{r+1:n}^m, T^o_{1:r}, \delta_{1:n})$. 

As the parameter estimates update, the imputations get better. As the imputations get better, the parameter estimates improve. Over time the process yields draws from the joint posterior $p(\beta, b, T_{r+1:n}^m | T^o_{1:r}, \delta_{1:n})$

We retain the sample of $(\beta, b)$ for inference and toss samples of $T^m$

## Simulation Example in R

All of the code can be found on my [GitHub](https://github.com/stablemarkets/BayesianTutorials/tree/master/BayesianSurvival). Here I simulate a data set with three covariates for 1,000 subjects with censoring and survival times independently drawn from a Weibull. 

```{r helpers, echo=F, warning=F, error=F, include=F}
log_post_a <- function(beta, b, X, survt){ # shape
  
  a <- exp( X %*% beta )

  lik <- sum(dweibull( survt, shape = a, scale = exp(b), log=T))
  pr <- sum(dnorm(x = beta, mean = 0, sd = 100, log = T))
  return(lik + pr)
}

log_post_b <- function(b, beta, X, survt){ # scale
  a <- exp( X %*% beta )
    
  lik <- sum(dweibull( survt, shape = a, scale = exp(b), log=T))
  pr <- dexp(x = exp(b), rate = 1, log = T)
  return(lik + pr)
}


metrop_hastings<-function(x_0, iter=1, log_post_density,
                          proposal_dist = function(x, prop_sigma){ 
                            MASS::mvrnorm(1, mu = x, Sigma = prop_sigma )
                          }, 
                          lower=-Inf, upper=Inf, prop_sigma,
                          ... ){
  for(i in 1:iter){
    # draw from proposal distribution
    x_star <- proposal_dist(x_0, prop_sigma) 
    
    # calculate ratio of conditional posterior densities
    r_num <- do.call(log_post_density, c(list(x_star), list(...)) )
    r_denom <- do.call(log_post_density, c(list(x_0), list(...)) )
    r <- exp(r_num - r_denom)
    rmin<-min(r,1)
    if(is.na(rmin)) browser()
    # accept / reject proposal
    if(rbinom(1,1,rmin)==1){ 
      x_0<-x_star
    }
  }
  
  res<-list(x_0 = x_0, accept_prob = rmin )
  return(res)
}
```


```{r simulate_data, echo=F, warning=F, error=F, cache=T}
library(survival)
library(truncdist)

################################################################################
### 0 - Simulate Data
################################################################################
set.seed(1)

n <- 1000
x1 <- rnorm(n)
x2 <- rnorm(n)
A <- rbinom(n, 1, .5)

X <- model.matrix(~ x1 + x2 + A)

true_beta <- matrix(c(1, .5, -.5, 1), ncol=1)
true_shape <- exp(X %*% true_beta)
true_scale <- 1

# simulate censoring and survival times
survt = rweibull(n, true_shape, true_scale) 
cent = rweibull(n, true_shape, true_scale)

## observed data:
#censoring indicator
delta <- cent < survt
survt[delta==1] <- cent[delta==1] # censor survival time.
```

Here are the results using the augmentated sampler described above. The posterior distribution of survival is concentrated around the truth. The Kaplan-Meier also does a nice job, but gives noisier estimates near the end.

```{r augmented_sampler, echo=F, warning=F, error=F, cache=T}

################################################################################
### 1 - Run Augmented Sampler Accounting for Censoring 
################################################################################
iter <- 10000 # number of gibbs iterations

# shells for storing parameters
bshell <- matrix(NA, nrow=4, ncol = iter)
scaleshell <- numeric(iter)

scaleshell[1] <- c(0)
bshell[,1] <- c(0,0,0,0)

survt_all <- survt
n_miss <- sum(delta)
row_miss <- c(1:n)[delta]

par(mfrow=c(1,1))
plot(survfit(Surv(survt, 1-delta) ~ 1),conf.int = F, col='green',
     xlab=c('Time'),ylab='Survival Probability',
     main = 'Data augmentation with all subjects')

prop_covar <- diag(c(.0001,.0001,.0001,.0001))

for(i in 2:iter){
  ## sample from posterior of parameters, 
  ## conditional on observed and missing survival times
  bshell[,i] <- metrop_hastings(x_0 = bshell[,i-1, drop=F], iter = 1,
                                log_post_density = log_post_a,
                                prop_sigma = prop_covar, 
                                X=X, survt=survt_all, b=scaleshell[i-1] )$x_0
  
  scaleshell[i] <- metrop_hastings(x_0 = scaleshell[i-1], iter = 1,
                                   log_post_density = log_post_b,
                                   prop_sigma = matrix(.0001), 
                                   X=X, survt=survt_all, 
                                   beta=bshell[, i, drop=F] )$x_0
  
  ## sample from conditional posterior of missing survival times
  for(m in row_miss){
    survt_all[m] <- rtrunc(1, spec = 'weibull', 
                           a = survt[m], 
                           shape = exp( X[m,,drop=F] %*% bshell[,i, drop=F] ) , 
                           scale =  exp(scaleshell[i]) )
  }
  
  if(i>9500){
    post_draw <- rweibull(n, 
                          shape =  exp(X %*% bshell[,i,drop=F]), 
                          scale = rep(exp(scaleshell[i]), n)  )
    post_ecdf <- ecdf(post_draw)
    curve(1-post_ecdf(x), add=T, from=0, to=4, col='gray')
  }
  
}

prior_draw <- rweibull(1000, 
                       shape = exp(X %*% true_beta), 
                       scale = true_scale  )
prior_ecdf <- ecdf(prior_draw)
curve(1-prior_ecdf(x), add=T, from=0, to=4, col='red', lwd=2)

lines(survfit(Surv(survt, 1-delta) ~ 1),conf.int = F, col='green', lwd=2)
legend('topright',
       legend=c('Kaplan-Meier', 
                'Posterior Survival Draws',
                'True Survival Curve'),
       col=c('green','gray','red'), bty='n', lty=c(1,1,1))
```

Below the Weibull survival estimated using only uncensored data. The Kaplan-Meier is estimated using all the data. As expected, ignoring censored subjects leads us to underestimate survival.
```{r naive_analysis, echo=F, warning=F, error=F, cache=T}
################################################################################
### 2 - Run Sampler with only uncensored patients
################################################################################
survt_obs <- survt[delta!=1]
X_obs <- X[delta!=1, ]

plot(survfit(Surv(survt, 1-delta) ~ 1), conf.int=F,col='green',
     xlab=c('Time'),ylab='Survival Probability',
     main = 'Metropolis with only uncensored subjects')

for(i in 2:iter){
  bshell[,i] <- metrop_hastings(x_0 = bshell[,i-1, drop=F], iter = 1,
                                log_post_density = log_post_a,
                                prop_sigma = prop_covar, 
                                X=X_obs, survt=survt_obs,b=scaleshell[i-1] )$x_0
  
  scaleshell[i] <- metrop_hastings(x_0 = scaleshell[i-1], iter = 1,
                                    log_post_density = log_post_b,
                                    prop_sigma = matrix(.0001), 
                                    X=X_obs, survt=survt_obs, 
                                    beta=bshell[, i, drop=F] )$x_0
  
  if(i>9500){
    post_draw <- rweibull(nrow(X_obs), 
                          shape =  exp(X_obs %*% bshell[,i,drop=F]), 
                          scale = rep(exp(scaleshell[i]), n)  )
    post_ecdf <- ecdf(post_draw)
    curve(1-post_ecdf(x), add=T, from=0, to=4, col='gray')
  }
  
}

prior_draw <- rweibull(1000, 
                       shape = exp(X_obs %*% true_beta), 
                       scale = true_scale  )
prior_ecdf <- ecdf(prior_draw)
curve(1-prior_ecdf(x), add=T, from=0, to=4, col='red', lwd=2)

legend('topright',
       legend=c('Kaplan-Meier', 
                'Posterior Survival Draws', 
                'True Survival Curve'),
       col=c('green','gray','red'), bty='n', lty=c(1,1,1))

lines(survfit(Surv(survt, 1-delta) ~ 1), conf.int=F,col='green', lwd=2)
```


